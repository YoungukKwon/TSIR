{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b5d992",
   "metadata": {},
   "source": [
    "## Low-Rank Autoregressive Tensor Completion (LATC)\n",
    "\n",
    "This notebook shows how to implement a LATC (with truncated nuclear norm) imputer on some real-world traffic data sets. To overcome the problem of missing values within multivariate time series data, this method takes into account both low-rank structure and time series regression. For an in-depth discussion of LATC, please see [1].\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=\"black\">\n",
    "<b>[1]</b> Xinyu Chen, Mengying Lei, Nicolas Saunier, Lijun Sun (2021). <b>Low-Rank Autorgressive Tensor Completion for Spatiotemporal Traffic Data Imputation</b>. arXiv:2104.14936. <a href=\"https://arxiv.org/abs/2104.14936\" title=\"PDF\"><b>[PDF]</b></a> \n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3449760f",
   "metadata": {},
   "source": [
    "### Define LATC-imputer kernel\n",
    "\n",
    "We start by introducing some necessary functions that relies on `Numpy`.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>ten2mat</code>:</b> <font color=\"black\">Unfold tensor as matrix by specifying mode.</font></li>\n",
    "<li><b><code>mat2ten</code>:</b> <font color=\"black\">Fold matrix as tensor by specifying dimension (i.e, tensor size) and mode.</font></li>\n",
    "<li><b><code>svt_tnn</code>:</b> <font color=\"black\">Implement the process of Singular Value Thresholding (SVT).</font></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2e455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')\n",
    "\n",
    "def mat2ten(mat, tensor_size, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(tensor_size.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, tensor_size[index].tolist(), order = 'F'), 0, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "728490ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svt_tnn(mat, tau, theta):\n",
    "    [m, n] = mat.shape\n",
    "    if 2 * m < n:\n",
    "        u, s, v = np.linalg.svd(mat @ mat.T, full_matrices = 0)\n",
    "        s = np.sqrt(s)\n",
    "        idx = np.sum(s > tau)\n",
    "        mid = np.zeros(idx)\n",
    "        mid[: theta] = 1\n",
    "        mid[theta : idx] = (s[theta : idx] - tau) / s[theta : idx]\n",
    "        return (u[:, : idx] @ np.diag(mid)) @ (u[:, : idx].T @ mat)\n",
    "    elif m > 2 * n:\n",
    "        return svt_tnn(mat.T, tau, theta).T\n",
    "    u, s, v = np.linalg.svd(mat, full_matrices = 0)\n",
    "    idx = np.sum(s > tau)\n",
    "    vec = s[: idx].copy()\n",
    "    vec[theta : idx] = s[theta : idx] - tau\n",
    "    return u[:, : idx] @ np.diag(vec) @ v[: idx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5977582c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>compute_mape</code>:</b> <font color=\"black\">Compute the value of Mean Absolute Percentage Error (MAPE).</font></li>\n",
    "<li><b><code>compute_rmse</code>:</b> <font color=\"black\">Compute the value of Root Mean Square Error (RMSE).</font></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "> Note that $$\\mathrm{MAPE}=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\left|y_{i}-\\hat{y}_{i}\\right|}{y_{i}} \\times 100, \\quad\\mathrm{RMSE}=\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}},$$ where $n$ is the total number of estimated values, and $y_i$ and $\\hat{y}_i$ are the actual value and its estimation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd1629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c9bdda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(it, tol, var, var_hat):\n",
    "    print('Iter: {}'.format(it))\n",
    "    print('Tolerance: {:.6}'.format(tol))\n",
    "    print('Imputation MAPE: {:.6}'.format(compute_mape(var, var_hat)))\n",
    "    print('Imputation RMSE: {:.6}'.format(compute_rmse(var, var_hat)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8674909",
   "metadata": {},
   "source": [
    "How to create $\\boldsymbol{\\Psi}_{0},\\boldsymbol{\\Psi}_{1},\\ldots,\\boldsymbol{\\Psi}_{d}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "399f7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve as spsolve\n",
    "\n",
    "def generate_Psi(dim_time, time_lags):\n",
    "    Psis = []\n",
    "    max_lag = np.max(time_lags)\n",
    "    for i in range(len(time_lags) + 1):\n",
    "        row = np.arange(0, dim_time - max_lag)\n",
    "        if i == 0:\n",
    "            col = np.arange(0, dim_time - max_lag) + max_lag\n",
    "        else:\n",
    "            col = np.arange(0, dim_time - max_lag) + max_lag - time_lags[i - 1]\n",
    "        data = np.ones(dim_time - max_lag)\n",
    "        Psi = sparse.coo_matrix((data, (row, col)), shape = (dim_time - max_lag, dim_time))\n",
    "        Psis.append(Psi)\n",
    "    return Psis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34f78301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psi_0:\n",
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "\n",
      "Psi_1:\n",
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "Psi_2:\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example\n",
    "dim_time = 5\n",
    "time_lags = np.array([1, 3])\n",
    "Psis = generate_Psi(dim_time, time_lags)\n",
    "print('Psi_0:')\n",
    "print(Psis[0].toarray())\n",
    "print()\n",
    "print('Psi_1:')\n",
    "print(Psis[1].toarray())\n",
    "print()\n",
    "print('Psi_2:')\n",
    "print(Psis[2].toarray())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67cd7b5",
   "metadata": {},
   "source": [
    "The main idea behind LATC-imputer is to approximate partially observed data with both low-rank structure and time series dynamics. The following `latc` kernel includes some necessary inputs:\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>dense_tensor</code>:</b> <font color=\"black\">This is an input which has the ground truth for validation. If this input is not available, you could use <code>dense_tensor = sparse_tensor.copy()</code> instead.</font></li>\n",
    "<li><b><code>sparse_tensor</code>:</b> <font color=\"black\">This is a partially observed tensor which has many missing entries.</font></li>\n",
    "<li><b><code>time_lags</code>:</b> <font color=\"black\">Time lags, e.g., <code>time_lags = np.array([1, 2, 3])</code>. </font></li>\n",
    "<li><b><code>alpha</code>:</b> <font color=\"black\">Weights for tensors' nuclear norm, e.g., <code>alpha = np.ones(3) / 3</code>. </font></li>\n",
    "<li><b><code>rho</code>:</b> <font color=\"black\">Learning rate for ADMM, e.g., <code>rho = 0.0005</code>. </font></li>\n",
    "<li><b><code>lambda0</code>:</b> <font color=\"black\">Weight for time series regressor, e.g., <code>lambda0 = 5 * rho</code></font></li>\n",
    "<li><b><code>theta</code>:</b> <font color=\"black\">Integer-wise truncation for truncated nuclear norm, e.g., <code>theta = 5</code></font></li>\n",
    "<li><b><code>epsilon</code>:</b> <font color=\"black\">Stop criteria, e.g., <code>epsilon = 0.0001</code>. </font></li>\n",
    "<li><b><code>maxiter</code>:</b> <font color=\"black\">Maximum iteration to stop algorithm, e.g., <code>maxiter = 100</code>. </font></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbc00a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latc(dense_tensor, sparse_tensor, time_lags, alpha, rho0, lambda0, theta, \n",
    "         epsilon = 1e-4, maxiter = 100, K = 3):\n",
    "    \"\"\"Low-Rank Autoregressive Tensor Completion (LATC)\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    dim_time = int(np.prod(dim) / dim[0])\n",
    "    d = len(time_lags)\n",
    "    max_lag = np.max(time_lags)\n",
    "    sparse_mat = ten2mat(sparse_tensor, 0)\n",
    "    pos_missing = np.where(sparse_mat == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    dense_test = dense_tensor[pos_test]\n",
    "    del dense_tensor\n",
    "    \n",
    "    # Initialize T, Z, A\n",
    "    T = np.zeros(dim)\n",
    "    Z_tensor = sparse_tensor.copy()\n",
    "    Z = sparse_mat.copy()\n",
    "    A = 0.001 * np.random.rand(dim[0], d)\n",
    "    Psis = generate_Psi(dim_time, time_lags)\n",
    "    iden = sparse.coo_matrix((np.ones(dim_time), (np.arange(0, dim_time), np.arange(0, dim_time))), \n",
    "                             shape = (dim_time, dim_time))\n",
    "    it = 0\n",
    "    ind = np.zeros((d, dim_time - max_lag), dtype = np.int_)\n",
    "    for i in range(d):\n",
    "        ind[i, :] = np.arange(max_lag - time_lags[i], dim_time - time_lags[i])\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    rho = rho0\n",
    "    \n",
    "    used_time = 0\n",
    "    \n",
    "    # Main loop\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        temp = []\n",
    "        for m in range(dim[0]):\n",
    "            Psis0 = Psis.copy()\n",
    "            for i in range(d):\n",
    "                Psis0[i + 1] = A[m, i] * Psis[i + 1]\n",
    "            B = Psis0[0] - sum(Psis0[1 :])\n",
    "            temp.append(B.T @ B)\n",
    "            \n",
    "        # loop for ADMM\n",
    "        for k in range(K):\n",
    "            rho = min(rho * 1.05, 1e5)\n",
    "            tensor_hat = np.zeros(dim)\n",
    "            \n",
    "            # Update X\n",
    "            for p in range(len(dim)):\n",
    "                tensor_hat += alpha[p] * mat2ten(svt_tnn(ten2mat(Z_tensor - T / rho, p), \n",
    "                                                         alpha[p] / rho, theta), dim, p)\n",
    "                \n",
    "            # Update Z\n",
    "            temp0 = rho / lambda0 * ten2mat(tensor_hat + T / rho, 0)\n",
    "            mat = np.zeros((dim[0], dim_time))\n",
    "            for m in range(dim[0]):\n",
    "                mat[m, :] = spsolve(temp[m] + rho * iden / lambda0, temp0[m, :])\n",
    "            Z[pos_missing] = mat[pos_missing]\n",
    "            Z_tensor = mat2ten(Z, dim, 0)\n",
    "            \n",
    "            # Update T\n",
    "            T = T + rho * (tensor_hat - Z_tensor)\n",
    "        \n",
    "        # Update A\n",
    "        for m in range(dim[0]):\n",
    "            A[m, :] = np.linalg.lstsq(Z[m, ind].T, Z[m, max_lag :], rcond = None)[0]\n",
    "        mat_hat = ten2mat(tensor_hat, 0)\n",
    "        \n",
    "        \n",
    "        tol = np.linalg.norm((mat_hat - last_mat), 'fro') / snorm\n",
    "        last_mat = mat_hat.copy()\n",
    "        it += 1\n",
    "        if it % 20 == 0:\n",
    "            print(\"iter\", it, \"tole = %.5f\" % tol)\n",
    "            #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "            \n",
    "        used_time += time.time() - start_time\n",
    "        \n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "    #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "    mape = compute_mape(dense_test, tensor_hat[pos_test])\n",
    "    rmse = compute_rmse(dense_test, tensor_hat[pos_test])\n",
    "    \n",
    "    return tensor_hat, used_time, mape, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913afeb2",
   "metadata": {},
   "source": [
    "> We use `spslove` of `scipy.sparse.linalg` for updating $\\boldsymbol{Z}$ because computing the inverse of a large matrix directly is computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f3bb8",
   "metadata": {},
   "source": [
    "## LATC+HOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e571538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_(mat):\n",
    "    # faster SVD\n",
    "    [m, n] = mat.shape\n",
    "    try:\n",
    "        if 2 * m < n:\n",
    "            u, s, _ = np.linalg.svd(mat @ mat.T, full_matrices=False)\n",
    "            s = np.sqrt(s)\n",
    "            tol = n * torch.finfo(float).eps\n",
    "            idx = np.sum(s > tol)\n",
    "            return u[:, :idx], s[:idx],  np.diag(1/s[:idx]) @ u[:, :idx].T @ mat\n",
    "        elif m > 2 * n:\n",
    "            v, s, u = svd_(mat.T)\n",
    "            return u, s, v\n",
    "    except: \n",
    "        pass\n",
    "    u, s, v = np.linalg.svd(mat, full_matrices=False)\n",
    "    return u, s, v\n",
    "\n",
    "def ReLU(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def sir_shrinkage(vec, lam, sigma):\n",
    "    # Proximal operator P_(lambda,sigma)(x)\n",
    "    tmp = np.abs(vec)*(1 - np.exp((lam**2-vec**2)/(sigma**2)))\n",
    "    return np.sign(vec)*ReLU(tmp)\n",
    "\n",
    "def svt_sir(mat, lam, sigma, theta=0.1):\n",
    "    u, s, v = svd_(mat)\n",
    "    ss = s.copy()\n",
    "    r = int(np.ceil(theta * len(s)))\n",
    "    #r = 15\n",
    "    ss[r:] = sir_shrinkage(s[r:], lam, sigma)\n",
    "    idx = np.where(ss > 0)[0]\n",
    "    return u[:, idx] @ np.diag(ss[idx]) @ v[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e886641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latc_how(dense_tensor, sparse_tensor, time_lags, alpha, rho0, lambda0, theta, rhofac,\n",
    "             epsilon = 1e-4, maxiter = 200, K = 3):\n",
    "    \"\"\"Low-Rank Autoregressive Tensor Completion (LATC)\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    dim_time = int(np.prod(dim) / dim[0])\n",
    "    d = len(time_lags)\n",
    "    max_lag = np.max(time_lags)\n",
    "    sparse_mat = ten2mat(sparse_tensor, 0)\n",
    "    pos_missing = np.where(sparse_mat == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    dense_test = dense_tensor[pos_test]\n",
    "    del dense_tensor\n",
    "    \n",
    "    # Initialize T, Z, A\n",
    "    T = np.zeros(dim)\n",
    "    Z_tensor = sparse_tensor.copy()\n",
    "    Z = sparse_mat.copy()\n",
    "    A = 0.001 * np.random.rand(dim[0], d)\n",
    "    Psis = generate_Psi(dim_time, time_lags)\n",
    "    iden = sparse.coo_matrix((np.ones(dim_time), (np.arange(0, dim_time), np.arange(0, dim_time))), \n",
    "                             shape = (dim_time, dim_time))\n",
    "    it = 0\n",
    "    ind = np.zeros((d, dim_time - max_lag), dtype = np.int_)\n",
    "    for i in range(d):\n",
    "        ind[i, :] = np.arange(max_lag - time_lags[i], dim_time - time_lags[i])\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    rho = rho0\n",
    "    \n",
    "    used_time = 0\n",
    "    sigmafac = np.sqrt(2)\n",
    "    \n",
    "    # Main loop\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        temp = []\n",
    "        for m in range(dim[0]):\n",
    "            Psis0 = Psis.copy()\n",
    "            for i in range(d):\n",
    "                Psis0[i + 1] = A[m, i] * Psis[i + 1]\n",
    "            B = Psis0[0] - sum(Psis0[1 :])\n",
    "            temp.append(B.T @ B)\n",
    "            \n",
    "        # loop for ADMM\n",
    "        for k in range(K):\n",
    "            rho = min(rho * rhofac, 1e5)\n",
    "            tensor_hat = np.zeros(dim)\n",
    "            \n",
    "            # Update X\n",
    "            for p in range(len(dim)):\n",
    "                lam = alpha[p]/rho\n",
    "                sigma = lam*sigmafac\n",
    "                tmp_p = svt_sir(ten2mat(Z_tensor- T/rho, p), lam, sigma, theta)\n",
    "                tensor_hat += alpha[p]*mat2ten(tmp_p, dim, p)\n",
    "                #tensor_hat += alpha[p] * mat2ten(svt_tnn(ten2mat(Z_tensor - T / rho, p), \n",
    "                #                                         alpha[p] / rho, theta), dim, p)\n",
    "                \n",
    "            # Update Z\n",
    "            temp0 = rho / lambda0 * ten2mat(tensor_hat + T / rho, 0)\n",
    "            mat = np.zeros((dim[0], dim_time))\n",
    "            for m in range(dim[0]):\n",
    "                mat[m, :] = spsolve(temp[m] + rho * iden / lambda0, temp0[m, :])\n",
    "            Z[pos_missing] = mat[pos_missing]\n",
    "            Z_tensor = mat2ten(Z, dim, 0)\n",
    "            \n",
    "            # Update T\n",
    "            T = T + rho * (tensor_hat - Z_tensor)\n",
    "        \n",
    "        # Update A\n",
    "        for m in range(dim[0]):\n",
    "            A[m, :] = np.linalg.lstsq(Z[m, ind].T, Z[m, max_lag :], rcond = None)[0]\n",
    "        mat_hat = ten2mat(tensor_hat, 0)\n",
    "        \n",
    "        \n",
    "        tol = np.linalg.norm((mat_hat - last_mat), 'fro') / snorm\n",
    "        last_mat = mat_hat.copy()\n",
    "        it += 1\n",
    "        if it % 20 == 0:\n",
    "            print(\"iter\", it, \"tole = %.5f\" % tol)\n",
    "            #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "            \n",
    "        used_time += time.time() - start_time\n",
    "        \n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "    #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "    mape = compute_mape(dense_test, tensor_hat[pos_test])\n",
    "    rmse = compute_rmse(dense_test, tensor_hat[pos_test])\n",
    "    \n",
    "    return tensor_hat, used_time, mape, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e73705",
   "metadata": {},
   "source": [
    "## LATC+HOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e49cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THOC\n",
    "def hoc_shrinkage(vec, lam, gamma):\n",
    "    tmp = np.abs(vec) - (gamma**2 + lam**2)*np.abs(vec)/(gamma**2+vec**2)\n",
    "    return np.sign(vec)*ReLU(tmp)\n",
    "\n",
    "def svt_hoc(mat, lam, gamma, theta=0.1):    \n",
    "    u, s, v = svd_(mat)\n",
    "    ss = s.copy()\n",
    "    r = int(np.ceil(theta * len(s)))\n",
    "    #r = 15\n",
    "    ss[r:] = hoc_shrinkage(s[r:], lam, gamma)\n",
    "    idx = np.where(ss > 0)[0]\n",
    "    return u[:, idx] @ np.diag(ss[idx]) @ v[idx, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d330eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latc_hoc(dense_tensor, sparse_tensor, time_lags, alpha, rho0, lambda0, theta, rhofac,\n",
    "             epsilon = 1e-4, maxiter = 200, K = 3):\n",
    "    \"\"\"Low-Rank Autoregressive Tensor Completion (LATC)\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    dim_time = int(np.prod(dim) / dim[0])\n",
    "    d = len(time_lags)\n",
    "    max_lag = np.max(time_lags)\n",
    "    sparse_mat = ten2mat(sparse_tensor, 0)\n",
    "    pos_missing = np.where(sparse_mat == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    dense_test = dense_tensor[pos_test]\n",
    "    del dense_tensor\n",
    "    \n",
    "    # Initialize T, Z, A\n",
    "    T = np.zeros(dim)\n",
    "    Z_tensor = sparse_tensor.copy()\n",
    "    Z = sparse_mat.copy()\n",
    "    A = 0.001 * np.random.rand(dim[0], d)\n",
    "    Psis = generate_Psi(dim_time, time_lags)\n",
    "    iden = sparse.coo_matrix((np.ones(dim_time), (np.arange(0, dim_time), np.arange(0, dim_time))), \n",
    "                             shape = (dim_time, dim_time))\n",
    "    it = 0\n",
    "    ind = np.zeros((d, dim_time - max_lag), dtype = np.int_)\n",
    "    for i in range(d):\n",
    "        ind[i, :] = np.arange(max_lag - time_lags[i], dim_time - time_lags[i])\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    rho = rho0\n",
    "    \n",
    "    used_time = 0\n",
    "    sigmafac = np.sqrt(2)\n",
    "    \n",
    "    # Main loop\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        temp = []\n",
    "        for m in range(dim[0]):\n",
    "            Psis0 = Psis.copy()\n",
    "            for i in range(d):\n",
    "                Psis0[i + 1] = A[m, i] * Psis[i + 1]\n",
    "            B = Psis0[0] - sum(Psis0[1 :])\n",
    "            temp.append(B.T @ B)\n",
    "            \n",
    "        # loop for ADMM\n",
    "        for k in range(K):\n",
    "            rho = min(rho * rhofac, 1e5)\n",
    "            tensor_hat = np.zeros(dim)\n",
    "            \n",
    "            # Update X\n",
    "            for p in range(len(dim)):\n",
    "                lam = alpha[p]/rho\n",
    "                gamma = lam\n",
    "                tmp_p = svt_hoc(ten2mat(Z_tensor- T/rho, p), lam, gamma, theta)\n",
    "                tensor_hat += alpha[p]*mat2ten(tmp_p, dim, p)\n",
    "                #tensor_hat += alpha[p] * mat2ten(svt_tnn(ten2mat(Z_tensor - T / rho, p), \n",
    "                #                                         alpha[p] / rho, theta), dim, p)\n",
    "                \n",
    "            # Update Z\n",
    "            temp0 = rho / lambda0 * ten2mat(tensor_hat + T / rho, 0)\n",
    "            mat = np.zeros((dim[0], dim_time))\n",
    "            for m in range(dim[0]):\n",
    "                mat[m, :] = spsolve(temp[m] + rho * iden / lambda0, temp0[m, :])\n",
    "            Z[pos_missing] = mat[pos_missing]\n",
    "            Z_tensor = mat2ten(Z, dim, 0)\n",
    "            \n",
    "            # Update T\n",
    "            T = T + rho * (tensor_hat - Z_tensor)\n",
    "        \n",
    "        # Update A\n",
    "        for m in range(dim[0]):\n",
    "            A[m, :] = np.linalg.lstsq(Z[m, ind].T, Z[m, max_lag :], rcond = None)[0]\n",
    "        mat_hat = ten2mat(tensor_hat, 0)\n",
    "        \n",
    "        \n",
    "        tol = np.linalg.norm((mat_hat - last_mat), 'fro') / snorm\n",
    "        last_mat = mat_hat.copy()\n",
    "        it += 1\n",
    "        if it % 20 == 0:\n",
    "            print(\"iter\", it, \"tole = %.5f\" % tol)\n",
    "            #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "            \n",
    "        used_time += time.time() - start_time\n",
    "        \n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "    #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "    mape = compute_mape(dense_test, tensor_hat[pos_test])\n",
    "    rmse = compute_rmse(dense_test, tensor_hat[pos_test])\n",
    "    \n",
    "    return tensor_hat, used_time, mape, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c8adc",
   "metadata": {},
   "source": [
    "## LATC+HOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "896983b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THOP\n",
    "def hop_shrinkage(vec, lam, p):\n",
    "    tmp = np.abs(vec)-(lam**(2-p))*(np.abs(vec)**(p-1))\n",
    "    return np.sign(vec)*ReLU(tmp)\n",
    "\n",
    "def svt_hop(mat, lam, p, theta=0.1):    \n",
    "    u, s, v = svd_(mat)\n",
    "    ss = s.copy()\n",
    "    r = int(np.ceil(theta * len(s)))\n",
    "    #r = 15\n",
    "    ss[r:] = hop_shrinkage(s[r:], lam, p)\n",
    "    idx = np.where(ss > 0)[0]\n",
    "    return u[:, idx] @ np.diag(ss[idx]) @ v[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab463057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latc_hop(dense_tensor, sparse_tensor, time_lags, alpha, rho0, lambda0, theta, rhofac, p_hop,\n",
    "             epsilon = 1e-4, maxiter = 200, K = 3):\n",
    "    \"\"\"Low-Rank Autoregressive Tensor Completion (LATC)\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    dim_time = int(np.prod(dim) / dim[0])\n",
    "    d = len(time_lags)\n",
    "    max_lag = np.max(time_lags)\n",
    "    sparse_mat = ten2mat(sparse_tensor, 0)\n",
    "    pos_missing = np.where(sparse_mat == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    dense_test = dense_tensor[pos_test]\n",
    "    del dense_tensor\n",
    "    \n",
    "    # Initialize T, Z, A\n",
    "    T = np.zeros(dim)\n",
    "    Z_tensor = sparse_tensor.copy()\n",
    "    Z = sparse_mat.copy()\n",
    "    A = 0.001 * np.random.rand(dim[0], d)\n",
    "    Psis = generate_Psi(dim_time, time_lags)\n",
    "    iden = sparse.coo_matrix((np.ones(dim_time), (np.arange(0, dim_time), np.arange(0, dim_time))), \n",
    "                             shape = (dim_time, dim_time))\n",
    "    it = 0\n",
    "    ind = np.zeros((d, dim_time - max_lag), dtype = np.int_)\n",
    "    for i in range(d):\n",
    "        ind[i, :] = np.arange(max_lag - time_lags[i], dim_time - time_lags[i])\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    rho = rho0\n",
    "    \n",
    "    used_time = 0\n",
    "    sigmafac = np.sqrt(2)\n",
    "    #p_hop = 0.1\n",
    "    \n",
    "    # Main loop\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        temp = []\n",
    "        for m in range(dim[0]):\n",
    "            Psis0 = Psis.copy()\n",
    "            for i in range(d):\n",
    "                Psis0[i + 1] = A[m, i] * Psis[i + 1]\n",
    "            B = Psis0[0] - sum(Psis0[1 :])\n",
    "            temp.append(B.T @ B)\n",
    "            \n",
    "        # loop for ADMM\n",
    "        for k in range(K):\n",
    "            rho = min(rho * rhofac, 1e5)\n",
    "            tensor_hat = np.zeros(dim)\n",
    "            \n",
    "            # Update X\n",
    "            for p in range(len(dim)):\n",
    "                lam = alpha[p]/rho\n",
    "                gamma = lam\n",
    "                tmp_p = svt_hop(ten2mat(Z_tensor- T/rho, p), lam, p_hop, theta)\n",
    "                tensor_hat += alpha[p]*mat2ten(tmp_p, dim, p)\n",
    "                #tensor_hat += alpha[p] * mat2ten(svt_tnn(ten2mat(Z_tensor - T / rho, p), \n",
    "                #                                         alpha[p] / rho, theta), dim, p)\n",
    "                \n",
    "            # Update Z\n",
    "            temp0 = rho / lambda0 * ten2mat(tensor_hat + T / rho, 0)\n",
    "            mat = np.zeros((dim[0], dim_time))\n",
    "            for m in range(dim[0]):\n",
    "                mat[m, :] = spsolve(temp[m] + rho * iden / lambda0, temp0[m, :])\n",
    "            Z[pos_missing] = mat[pos_missing]\n",
    "            Z_tensor = mat2ten(Z, dim, 0)\n",
    "            \n",
    "            # Update T\n",
    "            T = T + rho * (tensor_hat - Z_tensor)\n",
    "        \n",
    "        # Update A\n",
    "        for m in range(dim[0]):\n",
    "            A[m, :] = np.linalg.lstsq(Z[m, ind].T, Z[m, max_lag :], rcond = None)[0]\n",
    "        mat_hat = ten2mat(tensor_hat, 0)\n",
    "        \n",
    "        \n",
    "        tol = np.linalg.norm((mat_hat - last_mat), 'fro') / snorm\n",
    "        last_mat = mat_hat.copy()\n",
    "        it += 1\n",
    "        if it % 20 == 0:\n",
    "            print(\"iter\", it, \"tole = %.5f\" % tol)\n",
    "            #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "            \n",
    "        used_time += time.time() - start_time\n",
    "        \n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "    #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "    mape = compute_mape(dense_test, tensor_hat[pos_test])\n",
    "    rmse = compute_rmse(dense_test, tensor_hat[pos_test])\n",
    "    \n",
    "    return tensor_hat, used_time, mape, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771d259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc16cabe",
   "metadata": {},
   "source": [
    "## Guangzhou (speed) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d46f295-637c-47d0-b75c-8cf020c2dd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 144, 61)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('guangzhou.mat')['tensor'].transpose(0, 2, 1)\n",
    "dim1, dim2, dim3 = dense_tensor.shape\n",
    "dim = dense_tensor.shape\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74703568-5743-42cf-bc71-bd54bcb498c6",
   "metadata": {},
   "source": [
    "### RM 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27c8e57b-e4a5-4036-b884-5c87bc1d1cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern RM missing rate = 0.3\n",
      "LATC-HOC 1\n",
      "iter 20 tole = 0.02038\n",
      "iter 40 tole = 0.00052\n",
      "mape 5.57219877672862\n",
      "rmse 2.5305093895936026\n",
      "LATC-HOC 2\n",
      "iter 20 tole = 0.02079\n",
      "iter 40 tole = 0.00053\n",
      "mape 5.604099116966469\n",
      "rmse 2.538454448085459\n",
      "LATC-HOC 3\n",
      "iter 20 tole = 0.02084\n",
      "iter 40 tole = 0.00053\n",
      "mape 5.580048628172368\n",
      "rmse 2.5336931363864874\n",
      "LATC-HOC 4\n",
      "iter 20 tole = 0.02077\n",
      "iter 40 tole = 0.00053\n",
      "mape 5.581619882722197\n",
      "rmse 2.5329921501975554\n",
      "LATC-HOC 5\n",
      "iter 20 tole = 0.02089\n",
      "iter 40 tole = 0.00052\n",
      "mape 5.570679881468758\n",
      "rmse 2.5360685167487826\n",
      "2324.9911229610443\n"
     ]
    }
   ],
   "source": [
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "mape5_latc = []\n",
    "rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "#mape5_how = []\n",
    "#rmse5_how = []\n",
    "\n",
    "mape5_hop3 = []\n",
    "rmse5_hop3 = []\n",
    "\n",
    "mape5_hop6 = []\n",
    "rmse5_hop6 = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.3\n",
    "missing_case = \"RM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 12\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 40\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "\n",
    "    ## LATC-HOW\n",
    "    c = 10\n",
    "    rho = 1e-4\n",
    "    lambda0 = c * rho\n",
    "    theta_how = 0.2\n",
    "    rhofac = 1.1\n",
    "    Xest, time_lathow, mape_how, rmse_how = latc_how(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                     alpha, rho, lambda0, theta_how, rhofac, epsilon=1e-4)\n",
    "    print(\"mape\", mape_how*100)\n",
    "    print(\"rmse\", rmse_how)\n",
    "    mape5_hoc.append(mape_how)\n",
    "    rmse5_hoc.append(rmse_how)\n",
    "    \n",
    "    ### LATC-HOC ###\n",
    "    #print(\"LATC-HOC\", seed)\n",
    "    #c = 10\n",
    "    #rho = 5e-5\n",
    "    #lambda0 = c * rho\n",
    "    #theta_hoc = 0.2\n",
    "    #\n",
    "    #rhofac = 1.05\n",
    "    #Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                              alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    #print(\"mape\", mape_hoc*100)\n",
    "    #print(\"rmse\", rmse_hoc)\n",
    "    #mape5_hoc.append(mape_hoc)\n",
    "    #rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP (p=0.3) ###\n",
    "    #print(\"LATC-HOP3\", seed)\n",
    "    #c = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #theta_hop = 0.05\n",
    "    #p_hop = 0.3\n",
    "    \n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hop3, mape_hop3, rmse_hop3 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #mape5_hop3.append(mape_hop3)\n",
    "    #rmse5_hop3.append(rmse_hop3)\n",
    "    \n",
    "    ### LATC-HOP (p=0.6) ###\n",
    "    #print(\"LATC-HOP6\", seed)\n",
    "    #p_hop = 0.6\n",
    "    #\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hop6, mape_hop6, rmse_hop6 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #mape5_hop6.append(mape_hop6)\n",
    "    #rmse5_hop6.append(rmse_hop6)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c46fc766-08e0-4698-aee3-663ea63bdd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: 5.58\n",
      "LATC-HOP(p=0.3): nan\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: 2.53\n",
      "LATC-HOP(p=0.3): nan\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop3)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(mape5_hop6)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop3),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(rmse5_hop6),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069ebb4-1d27-4bbd-b64f-2530315bb049",
   "metadata": {},
   "source": [
    "### RM 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a980447-86bd-42ac-b1b7-4c0053bdbcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern RM missing rate = 0.5\n",
      "LATC-HOP3 1\n",
      "iter 20 tole = 0.00125\n",
      "mape 6.124293782440069\n",
      "rmse 2.7713921160024317\n",
      "LATC-HOP3 2\n",
      "iter 20 tole = 0.00125\n",
      "mape 6.1558125249875415\n",
      "rmse 2.777767087916753\n",
      "LATC-HOP3 3\n",
      "iter 20 tole = 0.00125\n",
      "mape 6.130408289504487\n",
      "rmse 2.7696910164990842\n",
      "LATC-HOP3 4\n",
      "iter 20 tole = 0.00126\n",
      "mape 6.136393666670139\n",
      "rmse 2.775017689371957\n",
      "LATC-HOP3 5\n",
      "iter 20 tole = 0.00126\n",
      "mape 6.125548574994409\n",
      "rmse 2.779591551262725\n",
      "1245.5528960227966\n"
     ]
    }
   ],
   "source": [
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "mape5_latc = []\n",
    "rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "mape5_how = []\n",
    "rmse5_how = []\n",
    "\n",
    "mape5_hop3 = []\n",
    "rmse5_hop3 = []\n",
    "\n",
    "mape5_hop6 = []\n",
    "rmse5_hop6 = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.5\n",
    "missing_case = \"RM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 12\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 30\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "    \n",
    "    ## LATC-HOW\n",
    "    #c = 10\n",
    "    #rho = 1e-4\n",
    "    #lambda0 = c * rho\n",
    "    #theta_how = 0.2\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_lathow, mape_how, rmse_how = latc_how(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_how, rhofac, epsilon=1e-4)\n",
    "    #print(\"mape\", mape_how*100)\n",
    "    #print(\"rmse\", rmse_how)\n",
    "    #mape5_hoc.append(mape_how)\n",
    "    #rmse5_hoc.append(rmse_how)\n",
    "\n",
    "    \n",
    "    ### LATC-HOC ###\n",
    "    #print(\"LATC-HOC\", seed)\n",
    "    #c = 10\n",
    "    #rho = 1e-4\n",
    "    #lambda0 = c * rho\n",
    "    #theta_hoc = 0.2\n",
    "    #\n",
    "    #rhofac = 1.05\n",
    "    #Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                              alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    #print(\"mape\", mape_hoc*100)\n",
    "    #print(\"rmse\", rmse_hoc)\n",
    "    #mape5_hoc.append(mape_hoc)\n",
    "    #rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP (p=0.3) ###\n",
    "    print(\"LATC-HOP3\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-4\n",
    "    lambda0 = c * rho\n",
    "    theta_hop = 0.2\n",
    "    p_hop = 0.2\n",
    "    \n",
    "    rhofac = 1.1\n",
    "    Xest, time_hop3, mape_hop3, rmse_hop3 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                     alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    print(\"mape\", mape_hop3*100)\n",
    "    print(\"rmse\", rmse_hop3)\n",
    "    mape5_hop3.append(mape_hop3)\n",
    "    rmse5_hop3.append(rmse_hop3)\n",
    "    \n",
    "    #### LATC-HOP (p=0.6) ###\n",
    "    #print(\"LATC-HOP6\", seed)\n",
    "    #p_hop = 0.6\n",
    "    #\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hop6, mape_hop6, rmse_hop6 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #mape5_hop6.append(mape_hop6)\n",
    "    #rmse5_hop6.append(rmse_hop6)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "96e6810d-a05f-40a3-ae0f-dd6ddd24dbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 6.13\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 2.77\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop3)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(mape5_hop6)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop3),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(rmse5_hop6),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9541ae-5c87-42b3-a117-661db6de8fc6",
   "metadata": {},
   "source": [
    "### RM 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ef8698b-4e7f-47af-ad71-255404a602eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern RM missing rate = 0.7\n",
      "LATC-HOP3 1\n",
      "iter 20 tole = 0.00215\n",
      "mape 7.049523651752268\n",
      "rmse 3.1494670417789057\n",
      "LATC-HOP3 2\n",
      "iter 20 tole = 0.00213\n",
      "mape 7.067551486152146\n",
      "rmse 3.14870563550281\n",
      "LATC-HOP3 3\n",
      "iter 20 tole = 0.00215\n",
      "mape 7.073502055214244\n",
      "rmse 3.155061557716629\n",
      "LATC-HOP3 4\n",
      "iter 20 tole = 0.00216\n",
      "mape 7.053453258736448\n",
      "rmse 3.155710626408283\n",
      "LATC-HOP3 5\n",
      "iter 20 tole = 0.00215\n",
      "mape 7.0706238990219745\n",
      "rmse 3.153262384761381\n",
      "1401.3301401138306\n"
     ]
    }
   ],
   "source": [
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "mape5_latc = []\n",
    "rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "#mape5_how = []\n",
    "#rmse5_how = []\n",
    "\n",
    "mape5_hop3 = []\n",
    "rmse5_hop3 = []\n",
    "\n",
    "mape5_hop6 = []\n",
    "rmse5_hop6 = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.7\n",
    "missing_case = \"RM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 12\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 15\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                       #alpha, rho, lambda0, theta)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "\n",
    "    ## LATC-HOW\n",
    "    #c = 10\n",
    "    #rho = 1e-4\n",
    "    #lambda0 = c * rho\n",
    "    #theta_how = 0.15\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_lathow, mape_how, rmse_how = latc_how(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_how, rhofac, epsilon=1e-4)\n",
    "    #print(\"mape\", mape_how*100)\n",
    "    #print(\"rmse\", rmse_how)\n",
    "    #mape5_hoc.append(mape_how)\n",
    "    #rmse5_hoc.append(rmse_how)\n",
    "       \n",
    "    ### LATC-HOC ###\n",
    "    #print(\"LATC-HOC\", seed)\n",
    "    #c = 10\n",
    "    #rho = 5e-5\n",
    "    #lambda0 = c * rho\n",
    "    #theta_hoc = 0.1\n",
    "    \n",
    "    #rhofac = 1.05\n",
    "    #Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                              alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    #print(\"MAPE:\",mape_hoc*100)\n",
    "    #print(\"RMSE:\",rmse_hoc)\n",
    "    #mape5_hoc.append(mape_hoc)\n",
    "    #rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP (p=0.3) ###\n",
    "    print(\"LATC-HOP3\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-4\n",
    "    lambda0 = c * rho\n",
    "    theta_hop = 0.2\n",
    "    p_hop = 0.2\n",
    "    \n",
    "    rhofac = 1.1\n",
    "    Xest, time_hop3, mape_hop3, rmse_hop3 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                     alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    print(\"mape\", mape_hop3*100)\n",
    "    print(\"rmse\", rmse_hop3)\n",
    "    mape5_hop3.append(mape_hop3)\n",
    "    rmse5_hop3.append(rmse_hop3)\n",
    "    #\n",
    "    #### LATC-HOP (p=0.6) ###\n",
    "    #print(\"LATC-HOP6\", seed)\n",
    "    #p_hop = 0.6\n",
    "    #\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hop6, mape_hop6, rmse_hop6 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #mape5_hop6.append(mape_hop6)\n",
    "    #rmse5_hop6.append(rmse_hop6)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40efcfc5-9932-4393-96bb-2b18a146ce1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 7.06\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 3.15\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop3)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(mape5_hop6)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop3),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(rmse5_hop6),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ba6967-7adf-4dfb-8e2e-00fd0eaec593",
   "metadata": {},
   "source": [
    "### NM 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f9d8f29-7c02-4945-b6ae-c1de8f96bbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 288, 44)\n",
      "start\n",
      "missing pattern NM missing rate = 0.3\n",
      "LATC-HOC 1\n",
      "iter 20 tole = 0.03716\n",
      "iter 40 tole = 0.00057\n",
      "MAPE: 7.09425264178355\n",
      "RMSE: 5.017769678677408\n",
      "LATC-HOC 2\n",
      "iter 20 tole = 0.03747\n",
      "iter 40 tole = 0.00056\n",
      "MAPE: 7.144104298743528\n",
      "RMSE: 5.030588772027354\n",
      "LATC-HOC 3\n",
      "iter 20 tole = 0.03845\n",
      "iter 40 tole = 0.00058\n",
      "MAPE: 6.8754298877799185\n",
      "RMSE: 4.900990386757416\n",
      "LATC-HOC 4\n",
      "iter 20 tole = 0.03853\n",
      "iter 40 tole = 0.00058\n",
      "MAPE: 7.203577911593376\n",
      "RMSE: 5.070323293432002\n",
      "LATC-HOC 5\n",
      "iter 20 tole = 0.03778\n",
      "iter 40 tole = 0.00056\n",
      "MAPE: 7.195797500950947\n",
      "RMSE: 5.065734425944471\n",
      "2953.6432268619537\n"
     ]
    }
   ],
   "source": [
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "mape5_latc = []\n",
    "rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "#mape5_how = []\n",
    "#rmse5_how = []\n",
    "\n",
    "mape5_hop3 = []\n",
    "rmse5_hop3 = []\n",
    "\n",
    "mape5_hop6 = []\n",
    "rmse5_hop6 = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.3\n",
    "missing_case = \"NM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 12\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 15\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "    \n",
    "    ## LATC-HOW\n",
    "    print(\"LATC-HOW\",seed)\n",
    "    c = 10\n",
    "    rho = 1e-4\n",
    "    lambda0 = c * rho\n",
    "    theta_how = 0.2\n",
    "    rhofac = 1.1\n",
    "    Xest, time_lathow, mape_how, rmse_how = latc_how(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                     alpha, rho, lambda0, theta_how, rhofac, epsilon=1e-4)\n",
    "    print(\"mape\", mape_how*100)\n",
    "    print(\"rmse\", rmse_how)\n",
    "    mape5_hoc.append(mape_how)\n",
    "    rmse5_hoc.append(rmse_how)\n",
    "        \n",
    "    ### LATC-HOC ###\n",
    "    print(\"LATC-HOC\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hoc = 0.05\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                  alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    print(\"MAPE:\", mape_hoc*100)\n",
    "    print(\"RMSE:\", rmse_hoc)\n",
    "    mape5_hoc.append(mape_hoc)\n",
    "    rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP (p=0.3) ###\n",
    "    #print(\"LATC-HOP3\", seed)\n",
    "    #c = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #theta_hop = 0.05\n",
    "    #p_hop = 0.3\n",
    "    #\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hop3, mape_hop3, rmse_hop3 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #mape5_hop3.append(mape_hop3)\n",
    "    #rmse5_hop3.append(rmse_hop3)\n",
    "    \n",
    "    ### LATC-HOP (p=0.6) ###\n",
    "    #print(\"LATC-HOP6\", seed)\n",
    "    #p_hop = 0.6\n",
    "    #\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hop6, mape_hop6, rmse_hop6 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #mape5_hop6.append(mape_hop6)\n",
    "    #rmse5_hop6.append(rmse_hop6)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a43ed8e2-4d3b-428a-9b26-9ee739178e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: 7.10\n",
      "LATC-HOP(p=0.3): nan\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: 5.02\n",
      "LATC-HOP(p=0.3): nan\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop3)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(mape5_hop6)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop3),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(rmse5_hop6),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af76494f-a0ed-49c3-916c-80002bc51126",
   "metadata": {},
   "source": [
    "### NM 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbbbcb8e-497d-47a0-b9be-7b8354985b55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern NM missing rate = 0.5\n",
      "iter 20 tole = 0.00138\n",
      "mape 9.74674680782956\n",
      "rmse 4.149793066271873\n",
      "iter 20 tole = 0.00137\n",
      "mape 9.809777825069874\n",
      "rmse 4.161916608742129\n",
      "iter 20 tole = 0.00139\n",
      "mape 9.847052101793832\n",
      "rmse 4.174148843079437\n",
      "iter 20 tole = 0.00139\n",
      "mape 9.838893808541075\n",
      "rmse 4.215105967118544\n",
      "iter 20 tole = 0.00141\n",
      "mape 9.839382446982798\n",
      "rmse 4.1749979167429485\n",
      "1170.7183728218079\n"
     ]
    }
   ],
   "source": [
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "mape5_latc = []\n",
    "rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "#mape5_how = []\n",
    "#rmse5_how = []\n",
    "\n",
    "mape5_hop3 = []\n",
    "rmse5_hop3 = []\n",
    "\n",
    "mape5_hop6 = []\n",
    "rmse5_hop6 = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.5\n",
    "missing_case = \"NM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 12\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "    \n",
    "    ## LATC-HOW\n",
    "    #print(\"LATC-HOW\",seed)\n",
    "    #c = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #theta_how = 0.05\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_lathow, mape_how, rmse_how = latc_how(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_how, rhofac, epsilon=1e-4)\n",
    "    #print(\"mape\", mape_how*100)\n",
    "    #print(\"rmse\", rmse_how)\n",
    "    #mape5_hoc.append(mape_how)\n",
    "    #rmse5_hoc.append(rmse_how)\n",
    "    \n",
    "    ### LATC-HOC ###\n",
    "    #print(\"LATC-HOC\", seed)\n",
    "    #c = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #theta_hoc = 0.05\n",
    "    \n",
    "    #rhofac = 1.05\n",
    "    #Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                              alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    #print(\"mape:\", mape_hoc*100)\n",
    "    #print(\"rmse\", rmse_hoc)\n",
    "    #mape5_hoc.append(mape_hoc)\n",
    "    #rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP (p=0.3) ###\n",
    "    print(\"LATC-HOP3\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hop = 0.05\n",
    "    p_hop = 0.2\n",
    "    \n",
    "    rhofac = 1.1\n",
    "    Xest, time_hop3, mape_hop3, rmse_hop3 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                     alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    print(\"mape\", mape_hop3*100)\n",
    "    print(\"rmse\", rmse_hop3)\n",
    "    mape5_hop3.append(mape_hop3)\n",
    "    rmse5_hop3.append(rmse_hop3)\n",
    "    \n",
    "    ### LATC-HOP (p=0.6) ###\n",
    "    #print(\"LATC-HOP6\", seed)\n",
    "    #p_hop = 0.6\n",
    "    #\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hop6, mape_hop6, rmse_hop6 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #mape5_hop6.append(mape_hop6)\n",
    "    #rmse5_hop6.append(rmse_hop6)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42adba99-ac69-4a1a-988c-580e0cff2185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 9.82\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 4.18\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop3)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(mape5_hop6)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop3),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(rmse5_hop6),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea237c5-4cad-45b4-84ab-8dadd80e7bcf",
   "metadata": {},
   "source": [
    "### NM 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3014b26-38b3-49ca-a353-4f06b14e81d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern NM missing rate = 0.7\n",
      "LATC-HOP3 1\n",
      "iter 20 tole = 0.00329\n",
      "mape 10.421782211336856\n",
      "rmse 4.368436895067339\n",
      "LATC-HOP3 2\n",
      "iter 20 tole = 0.00322\n",
      "mape 10.47084018333456\n",
      "rmse 4.391428148965082\n",
      "LATC-HOP3 3\n",
      "iter 20 tole = 0.00332\n",
      "mape 10.428682295602249\n",
      "rmse 4.360154485494678\n",
      "LATC-HOP3 4\n",
      "iter 20 tole = 0.00328\n",
      "mape 10.471251395449315\n",
      "rmse 4.407274318916716\n",
      "LATC-HOP3 5\n",
      "iter 20 tole = 0.00327\n",
      "mape 10.373528712999532\n",
      "rmse 4.339624325047629\n",
      "1294.1451609134674\n"
     ]
    }
   ],
   "source": [
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "mape5_latc = []\n",
    "rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "#mape5_how = []\n",
    "#rmse5_how = []\n",
    "\n",
    "mape5_hop3 = []\n",
    "rmse5_hop3 = []\n",
    "\n",
    "mape5_hop6 = []\n",
    "rmse5_hop6 = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.7\n",
    "missing_case = \"NM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 12\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 5\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "    \n",
    "    ## LATC-HOW\n",
    "    #print(\"LATC-HOW\",seed)\n",
    "    #c = 10\n",
    "    #rho = 1e-4\n",
    "    #lambda0 = c * rho\n",
    "    #theta_how = 0.2\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_lathow, mape_how, rmse_how = latc_how(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_how, rhofac, epsilon=1e-4)\n",
    "    #print(\"mape\", mape_how*100)\n",
    "    #print(\"rmse\", rmse_how)\n",
    "    #mape5_hoc.append(mape_how)\n",
    "    #rmse5_hoc.append(rmse_how)\n",
    "        \n",
    "    ### LATC-HOC ###\n",
    "    #print(\"LATC-HOC\", seed)\n",
    "    #c = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #theta_hoc = 0.03\n",
    "    #\n",
    "    #rhofac = 1.05\n",
    "    #Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                              alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    #print(\"mape:\", mape_hoc*100)\n",
    "    #print(\"rmse\", rmse_hoc)\n",
    "    #mape5_hoc.append(mape_hoc)\n",
    "    #rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP (p=0.3) ###\n",
    "    print(\"LATC-HOP3\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hop = 0.03\n",
    "    p_hop = 0.2\n",
    "    \n",
    "    rhofac = 1.1\n",
    "    Xest, time_hop3, mape_hop3, rmse_hop3 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                     alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    print(\"mape\", mape_hop3*100)\n",
    "    print(\"rmse\", rmse_hop3)\n",
    "    mape5_hop3.append(mape_hop3)\n",
    "    rmse5_hop3.append(rmse_hop3)\n",
    "    #\n",
    "    #### LATC-HOP (p=0.6) ###\n",
    "    #print(\"LATC-HOP6\", seed)\n",
    "    #p_hop = 0.6\n",
    "    #\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hop6, mape_hop6, rmse_hop6 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #mape5_hop6.append(mape_hop6)\n",
    "    #rmse5_hop6.append(rmse_hop6)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d241343-fd13-45a9-a8e4-a2456f44c454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 10.43\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 4.37\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop3)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(mape5_hop6)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop3),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(rmse5_hop6),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1076b96a-f277-4869-85cb-6112209abb07",
   "metadata": {},
   "source": [
    "### BM 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bffca39-34f0-4202-867b-3ecf6661c18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 288, 44)\n",
      "start\n",
      "missing pattern BM missing rate = 0.3\n",
      "LATC-HOC 1\n",
      "iter 20 tole = 0.02635\n",
      "iter 40 tole = 0.00047\n",
      "MAPE: 0.07600981033425229\n",
      "RMSE: 5.3382212793821795\n",
      "LATC-HOC 2\n",
      "iter 20 tole = 0.02814\n",
      "iter 40 tole = 0.00046\n",
      "MAPE: 0.08025604536817937\n",
      "RMSE: 5.533349704656068\n",
      "LATC-HOC 3\n",
      "iter 20 tole = 0.02759\n",
      "iter 40 tole = 0.00046\n",
      "MAPE: 0.07612254651421277\n",
      "RMSE: 5.277603750209328\n",
      "LATC-HOC 4\n",
      "iter 20 tole = 0.02633\n",
      "iter 40 tole = 0.00043\n",
      "MAPE: 0.07777150263445835\n",
      "RMSE: 5.416639994207868\n",
      "LATC-HOC 5\n",
      "iter 20 tole = 0.02615\n",
      "iter 40 tole = 0.00045\n",
      "MAPE: 0.07856236994298771\n",
      "RMSE: 5.4031821294472016\n",
      "3368.3796281814575\n"
     ]
    }
   ],
   "source": [
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "mape5_latc = []\n",
    "rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "#mape5_how = []\n",
    "#rmse5_how = []\n",
    "\n",
    "mape5_hop3 = []\n",
    "rmse5_hop3 = []\n",
    "\n",
    "mape5_hop6 = []\n",
    "rmse5_hop6 = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.3\n",
    "missing_case = \"BM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 6\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "    \n",
    "    ## LATC-HOW\n",
    "    print(\"LATC-HOW\",seed)\n",
    "    c = 10\n",
    "    rho = 1e-4\n",
    "    lambda0 = c * rho\n",
    "    theta_how = 0.2\n",
    "    rhofac = 1.1\n",
    "    Xest, time_lathow, mape_how, rmse_how = latc_how(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                     alpha, rho, lambda0, theta_how, rhofac, epsilon=1e-4)\n",
    "    print(\"mape\", mape_how*100)\n",
    "    print(\"rmse\", rmse_how)\n",
    "    mape5_hoc.append(mape_how)\n",
    "    rmse5_hoc.append(rmse_how)\n",
    "         \n",
    "    ### LATC-HOC ###\n",
    "    print(\"LATC-HOC\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hoc = 0.03\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                  alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    print(\"MAPE:\", mape_hoc*100)\n",
    "    print(\"RMSE:\", rmse_hoc)\n",
    "    mape5_hoc.append(mape_hoc)\n",
    "    rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP (p=0.3) ###\n",
    "    #print(\"LATC-HOP3\", seed)\n",
    "    #c = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #theta_hop = 0.03\n",
    "    #p_hop = 0.3\n",
    "    #\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hop3, mape_hop3, rmse_hop3 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #mape5_hop3.append(mape_hop3)\n",
    "    #rmse5_hop3.append(rmse_hop3)\n",
    "    #\n",
    "    #### LATC-HOP (p=0.6) ###\n",
    "    #print(\"LATC-HOP6\", seed)\n",
    "    #p_hop = 0.6\n",
    "    #\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hop6, mape_hop6, rmse_hop6 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #mape5_hop6.append(mape_hop6)\n",
    "    #rmse5_hop6.append(rmse_hop6)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e1e4baf-b725-46db-8284-e23f8be40168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: 7.77\n",
      "LATC-HOP(p=0.3): nan\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: 5.39\n",
      "LATC-HOP(p=0.3): nan\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop3)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(mape5_hop6)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop3),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(rmse5_hop6),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b19287-7ff0-4e28-8d8b-f53d2759b314",
   "metadata": {},
   "source": [
    "### BM 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf250565-afc1-45f0-b444-c88cf62c9bb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern BM missing rate = 0.5\n",
      "LATC-HOW 1\n",
      "iter 20 tole = 0.00286\n",
      "mape 9.765981863746322\n",
      "rmse 4.079390977778238\n",
      "LATC-HOW 2\n",
      "iter 20 tole = 0.00282\n",
      "mape 9.832787399520388\n",
      "rmse 4.091603462555295\n",
      "LATC-HOW 3\n",
      "iter 20 tole = 0.00283\n",
      "mape 9.60206494942288\n",
      "rmse 4.032737994352765\n",
      "LATC-HOW 4\n",
      "iter 20 tole = 0.00262\n",
      "mape 9.784050687071954\n",
      "rmse 4.0772234699036485\n",
      "LATC-HOW 5\n",
      "iter 20 tole = 0.00285\n",
      "mape 9.607012110742739\n",
      "rmse 4.01246316692899\n",
      "1228.0387160778046\n"
     ]
    }
   ],
   "source": [
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "mape5_latc = []\n",
    "rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "mape5_how = []\n",
    "rmse5_how = []\n",
    "\n",
    "mape5_hop3 = []\n",
    "rmse5_hop3 = []\n",
    "\n",
    "mape5_hop6 = []\n",
    "rmse5_hop6 = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.5\n",
    "missing_case = \"BM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 6\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "        \n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "    \n",
    "    ## LATC-HOW\n",
    "    print(\"LATC-HOW\",seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_how = 0.05\n",
    "    rhofac = 1.1\n",
    "    Xest, time_lathow, mape_how, rmse_how = latc_how(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                     alpha, rho, lambda0, theta_how, rhofac, epsilon=1e-4)\n",
    "    print(\"mape\", mape_how*100)\n",
    "    print(\"rmse\", rmse_how)\n",
    "    mape5_hoc.append(mape_how)\n",
    "    rmse5_hoc.append(rmse_how)\n",
    "        \n",
    "    ### LATC-HOC ###\n",
    "    #print(\"LATC-HOC\", seed)\n",
    "    #c = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #theta_hoc = 0.03\n",
    "    #\n",
    "    #rhofac = 1.05\n",
    "    #Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                              alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    #print(\"MAPE:\", mape_hoc*100)\n",
    "    #print(\"RMSE:\", rmse_hoc)\n",
    "    #mape5_hoc.append(mape_hoc)\n",
    "    #rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP (p=0.3) ###\n",
    "    #print(\"LATC-HOP3\", seed)\n",
    "    #c = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #theta_hop = 0.05\n",
    "    #p_hop = 0.2\n",
    "    #\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hop3, mape_hop3, rmse_hop3 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #print(\"MAPE\", mape_hop3*100)\n",
    "    #print(\"RMSE\", rmse_hop3)\n",
    "    #mape5_hop3.append(mape_hop3)\n",
    "    #rmse5_hop3.append(rmse_hop3)\n",
    "    \n",
    "    #### LATC-HOP (p=0.6) ###\n",
    "    #print(\"LATC-HOP6\", seed)\n",
    "    #p_hop = 0.6\n",
    "    #\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hop6, mape_hop6, rmse_hop6 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #mape5_hop6.append(mape_hop6)\n",
    "    #rmse5_hop6.append(rmse_hop6)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1cfd1bdc-7134-4dfe-823d-1ccd970d3f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATC-HOW: 9.72\n",
      "LATC-HOW: 4.06\n"
     ]
    }
   ],
   "source": [
    "print(\"LATC-HOW:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOW:\", format(np.mean(rmse5_hoc),\".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "552b4fab-c43c-4bb9-8c78-b28c9cc3f66b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 9.75\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 4.07\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop3)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(mape5_hop6)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop3),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(rmse5_hop6),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccc1d9b-2512-427c-95f5-c7e96cd34f43",
   "metadata": {},
   "source": [
    "### BM 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc792ee1-af46-44a6-8a40-56be0afa7c3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern BM missing rate = 0.7\n",
      "LATC-HOW 1\n",
      "iter 20 tole = 0.05938\n",
      "iter 40 tole = 0.00336\n",
      "iter 60 tole = 0.00014\n",
      "mape 10.874978042876144\n",
      "rmse 4.470293799591629\n",
      "LATC-HOW 2\n",
      "iter 20 tole = 0.06917\n",
      "iter 40 tole = 0.00333\n",
      "iter 60 tole = 0.00015\n",
      "mape 10.55013859360354\n",
      "rmse 4.390752003724729\n",
      "LATC-HOW 3\n",
      "iter 20 tole = 0.06629\n",
      "iter 40 tole = 0.00352\n",
      "iter 60 tole = 0.00015\n",
      "mape 10.633829392119274\n",
      "rmse 4.403232408252601\n",
      "LATC-HOW 4\n",
      "iter 20 tole = 0.06354\n",
      "iter 40 tole = 0.00307\n",
      "iter 60 tole = 0.00014\n",
      "mape 10.703906228182896\n",
      "rmse 4.418690535802969\n",
      "LATC-HOW 5\n",
      "iter 20 tole = 0.06498\n",
      "iter 40 tole = 0.00361\n",
      "iter 60 tole = 0.00015\n",
      "mape 10.601414326600024\n",
      "rmse 4.4030248351778765\n",
      "2585.915781021118\n"
     ]
    }
   ],
   "source": [
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "mape5_latc = []\n",
    "rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "mape5_how = []\n",
    "rmse5_how = []\n",
    "\n",
    "mape5_hop3 = []\n",
    "rmse5_hop3 = []\n",
    "\n",
    "mape5_hop6 = []\n",
    "rmse5_hop6 = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.7\n",
    "missing_case = \"BM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 6\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "    \n",
    "    ## LATC-HOW\n",
    "    print(\"LATC-HOW\",seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_how = 0.03\n",
    "    rhofac = 1.05\n",
    "    Xest, time_lathow, mape_how, rmse_how = latc_how(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                     alpha, rho, lambda0, theta_how, rhofac, epsilon=1e-4)\n",
    "    print(\"mape\", mape_how*100)\n",
    "    print(\"rmse\", rmse_how)\n",
    "    mape5_hoc.append(mape_how)\n",
    "    rmse5_hoc.append(rmse_how)\n",
    "        \n",
    "    ### LATC-HOC ###\n",
    "    #print(\"LATC-HOC\", seed)\n",
    "    #c = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #theta_hoc = 0.03\n",
    "    #\n",
    "    #rhofac = 1.1\n",
    "    #Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                              alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    #print(\"MAPE:\", mape_hoc*100)\n",
    "    #print(\"RMSE:\", rmse_hoc)    \n",
    "    #mape5_hoc.append(mape_hoc)\n",
    "    #rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP (p=0.3) ###\n",
    "    #print(\"LATC-HOP3\", seed)\n",
    "    #c = 10\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "    #theta_hop = 0.03\n",
    "    #p_hop = 0.2\n",
    "    #\n",
    "    #rhofac = 1.05\n",
    "    #Xest, time_hop3, mape_hop3, rmse_hop3 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #print(\"MAPE\", mape_hop3*100)\n",
    "    #print(\"RMSE\", rmse_hop3)\n",
    "    #mape5_hop3.append(mape_hop3)\n",
    "    #rmse5_hop3.append(rmse_hop3)\n",
    "\n",
    "    #### LATC-HOP (p=0.6) ###\n",
    "    #print(\"LATC-HOP6\", seed)\n",
    "    #p_hop = 0.6\n",
    "    #\n",
    "    #rhofac = 1.05\n",
    "    #Xest, time_hop6, mape_hop6, rmse_hop6 = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                 alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    #mape5_hop6.append(mape_hop6)\n",
    "    #rmse5_hop6.append(rmse_hop6)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f470903c-aaed-4000-8cb5-83bb915410b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATC-HOW: 10.67\n",
      "LATC-HOW: 4.42\n"
     ]
    }
   ],
   "source": [
    "print(\"LATC-HOW:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOW:\", format(np.mean(rmse5_hoc),\".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf19b172-cb56-4079-8deb-a58fc7339eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 10.69\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 4.42\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop3)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(mape5_hop6)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop3),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.6):\", format(np.mean(rmse5_hop6),\".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e124be1-15ef-4f68-b69b-7f153c344f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
