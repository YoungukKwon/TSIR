{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b5d992",
   "metadata": {},
   "source": [
    "## Traffic tensor completion using truncated sparsity-inducing regularizer\n",
    "- Main functions: LATC_HOC (THOC), LATC_HOP (THOP)\n",
    "- Refer to Chen et al. (2021) for LATC-related method (link: https://github.com/xinychen/transdim/blob/master/imputer/LATC.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78aaa88-bb5e-4f20-b28b-8a04725d37c6",
   "metadata": {},
   "source": [
    "## Functions for implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d2e455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')\n",
    "\n",
    "def mat2ten(mat, tensor_size, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(tensor_size.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, tensor_size[index].tolist(), order = 'F'), 0, mode)\n",
    "\n",
    "def svt_tnn(mat, tau, theta):\n",
    "    [m, n] = mat.shape\n",
    "    if 2 * m < n:\n",
    "        u, s, v = np.linalg.svd(mat @ mat.T, full_matrices = 0)\n",
    "        s = np.sqrt(s)\n",
    "        idx = np.sum(s > tau)\n",
    "        mid = np.zeros(idx)\n",
    "        mid[: theta] = 1\n",
    "        mid[theta : idx] = (s[theta : idx] - tau) / s[theta : idx]\n",
    "        return (u[:, : idx] @ np.diag(mid)) @ (u[:, : idx].T @ mat)\n",
    "    elif m > 2 * n:\n",
    "        return svt_tnn(mat.T, tau, theta).T\n",
    "    u, s, v = np.linalg.svd(mat, full_matrices = 0)\n",
    "    idx = np.sum(s > tau)\n",
    "    vec = s[: idx].copy()\n",
    "    vec[theta : idx] = s[theta : idx] - tau\n",
    "    return u[:, : idx] @ np.diag(vec) @ v[: idx, :]\n",
    "\n",
    "def svd_(mat):\n",
    "    # faster SVD\n",
    "    [m, n] = mat.shape\n",
    "    try:\n",
    "        if 2 * m < n:\n",
    "            u, s, _ = np.linalg.svd(mat @ mat.T, full_matrices=False)\n",
    "            s = np.sqrt(s)\n",
    "            tol = n * torch.finfo(float).eps\n",
    "            idx = np.sum(s > tol)\n",
    "            return u[:, :idx], s[:idx],  np.diag(1/s[:idx]) @ u[:, :idx].T @ mat\n",
    "        elif m > 2 * n:\n",
    "            v, s, u = svd_(mat.T)\n",
    "            return u, s, v\n",
    "    except: \n",
    "        pass\n",
    "    u, s, v = np.linalg.svd(mat, full_matrices=False)\n",
    "    return u, s, v\n",
    "\n",
    "def ReLU(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve as spsolve\n",
    "\n",
    "def generate_Psi(dim_time, time_lags):\n",
    "    Psis = []\n",
    "    max_lag = np.max(time_lags)\n",
    "    for i in range(len(time_lags) + 1):\n",
    "        row = np.arange(0, dim_time - max_lag)\n",
    "        if i == 0:\n",
    "            col = np.arange(0, dim_time - max_lag) + max_lag\n",
    "        else:\n",
    "            col = np.arange(0, dim_time - max_lag) + max_lag - time_lags[i - 1]\n",
    "        data = np.ones(dim_time - max_lag)\n",
    "        Psi = sparse.coo_matrix((data, (row, col)), shape = (dim_time - max_lag, dim_time))\n",
    "        Psis.append(Psi)\n",
    "    return Psis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969d509-e405-4e51-be66-6005e051a3b2",
   "metadata": {},
   "source": [
    "## LATC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbc00a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latc(dense_tensor, sparse_tensor, time_lags, alpha, rho0, lambda0, theta, \n",
    "         epsilon = 1e-4, maxiter = 100, K = 3):\n",
    "    \"\"\"Low-Rank Autoregressive Tensor Completion (LATC)\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    dim_time = int(np.prod(dim) / dim[0])\n",
    "    d = len(time_lags)\n",
    "    max_lag = np.max(time_lags)\n",
    "    sparse_mat = ten2mat(sparse_tensor, 0)\n",
    "    pos_missing = np.where(sparse_mat == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    dense_test = dense_tensor[pos_test]\n",
    "    del dense_tensor\n",
    "    \n",
    "    # Initialize T, Z, A\n",
    "    T = np.zeros(dim)\n",
    "    Z_tensor = sparse_tensor.copy()\n",
    "    Z = sparse_mat.copy()\n",
    "    A = 0.001 * np.random.rand(dim[0], d)\n",
    "    Psis = generate_Psi(dim_time, time_lags)\n",
    "    iden = sparse.coo_matrix((np.ones(dim_time), (np.arange(0, dim_time), np.arange(0, dim_time))), \n",
    "                             shape = (dim_time, dim_time))\n",
    "    it = 0\n",
    "    ind = np.zeros((d, dim_time - max_lag), dtype = np.int_)\n",
    "    for i in range(d):\n",
    "        ind[i, :] = np.arange(max_lag - time_lags[i], dim_time - time_lags[i])\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    rho = rho0\n",
    "    \n",
    "    used_time = 0\n",
    "    \n",
    "    # Main loop\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        temp = []\n",
    "        for m in range(dim[0]):\n",
    "            Psis0 = Psis.copy()\n",
    "            for i in range(d):\n",
    "                Psis0[i + 1] = A[m, i] * Psis[i + 1]\n",
    "            B = Psis0[0] - sum(Psis0[1 :])\n",
    "            temp.append(B.T @ B)\n",
    "            \n",
    "        # loop for ADMM\n",
    "        for k in range(K):\n",
    "            rho = min(rho * 1.05, 1e5)\n",
    "            tensor_hat = np.zeros(dim)\n",
    "            \n",
    "            # Update X\n",
    "            for p in range(len(dim)):\n",
    "                tensor_hat += alpha[p] * mat2ten(svt_tnn(ten2mat(Z_tensor - T / rho, p), \n",
    "                                                         alpha[p] / rho, theta), dim, p)\n",
    "                \n",
    "            # Update Z\n",
    "            temp0 = rho / lambda0 * ten2mat(tensor_hat + T / rho, 0)\n",
    "            mat = np.zeros((dim[0], dim_time))\n",
    "            for m in range(dim[0]):\n",
    "                mat[m, :] = spsolve(temp[m] + rho * iden / lambda0, temp0[m, :])\n",
    "            Z[pos_missing] = mat[pos_missing]\n",
    "            Z_tensor = mat2ten(Z, dim, 0)\n",
    "            \n",
    "            # Update T\n",
    "            T = T + rho * (tensor_hat - Z_tensor)\n",
    "        \n",
    "        # Update A\n",
    "        for m in range(dim[0]):\n",
    "            A[m, :] = np.linalg.lstsq(Z[m, ind].T, Z[m, max_lag :], rcond = None)[0]\n",
    "        mat_hat = ten2mat(tensor_hat, 0)\n",
    "        \n",
    "        \n",
    "        tol = np.linalg.norm((mat_hat - last_mat), 'fro') / snorm\n",
    "        last_mat = mat_hat.copy()\n",
    "        it += 1\n",
    "        if it % 20 == 0:\n",
    "            print(\"iter\", it, \"tole = %.5f\" % tol)\n",
    "            #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "            \n",
    "        used_time += time.time() - start_time\n",
    "        \n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "    #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "    mape = compute_mape(dense_test, tensor_hat[pos_test])\n",
    "    rmse = compute_rmse(dense_test, tensor_hat[pos_test])\n",
    "    \n",
    "    return tensor_hat, used_time, mape, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e73705",
   "metadata": {},
   "source": [
    "## LATC+HOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e49cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hoc_shrinkage(vec, lam, gamma):\n",
    "    tmp = np.abs(vec) - (gamma**2 + lam**2)*np.abs(vec)/(gamma**2+vec**2)\n",
    "    return np.sign(vec)*ReLU(tmp)\n",
    "\n",
    "def svt_hoc(mat, lam, gamma, theta=0.1):    \n",
    "    u, s, v = svd_(mat)\n",
    "    ss = s.copy()\n",
    "    r = int(np.ceil(theta * len(s)))\n",
    "    #r = 15\n",
    "    ss[r:] = hoc_shrinkage(s[r:], lam, gamma)\n",
    "    idx = np.where(ss > 0)[0]\n",
    "    return u[:, idx] @ np.diag(ss[idx]) @ v[idx, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d330eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latc_hoc(dense_tensor, sparse_tensor, time_lags, alpha, rho0, lambda0, theta, rhofac,\n",
    "             epsilon = 1e-4, maxiter = 200, K = 3):\n",
    "    \"\"\" Truncated hybrid-ordinary Cauchy (THOC)\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    dim_time = int(np.prod(dim) / dim[0])\n",
    "    d = len(time_lags)\n",
    "    max_lag = np.max(time_lags)\n",
    "    sparse_mat = ten2mat(sparse_tensor, 0)\n",
    "    pos_missing = np.where(sparse_mat == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    dense_test = dense_tensor[pos_test]\n",
    "    del dense_tensor\n",
    "    \n",
    "    # Initialize T, Z, A\n",
    "    T = np.zeros(dim)\n",
    "    Z_tensor = sparse_tensor.copy()\n",
    "    Z = sparse_mat.copy()\n",
    "    A = 0.001 * np.random.rand(dim[0], d)\n",
    "    Psis = generate_Psi(dim_time, time_lags)\n",
    "    iden = sparse.coo_matrix((np.ones(dim_time), (np.arange(0, dim_time), np.arange(0, dim_time))), \n",
    "                             shape = (dim_time, dim_time))\n",
    "    it = 0\n",
    "    ind = np.zeros((d, dim_time - max_lag), dtype = np.int_)\n",
    "    for i in range(d):\n",
    "        ind[i, :] = np.arange(max_lag - time_lags[i], dim_time - time_lags[i])\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    rho = rho0\n",
    "    \n",
    "    used_time = 0\n",
    "    sigmafac = np.sqrt(2)\n",
    "    \n",
    "    # Main loop\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        temp = []\n",
    "        for m in range(dim[0]):\n",
    "            Psis0 = Psis.copy()\n",
    "            for i in range(d):\n",
    "                Psis0[i + 1] = A[m, i] * Psis[i + 1]\n",
    "            B = Psis0[0] - sum(Psis0[1 :])\n",
    "            temp.append(B.T @ B)\n",
    "            \n",
    "        # loop for ADMM\n",
    "        for k in range(K):\n",
    "            rho = min(rho * rhofac, 1e5)\n",
    "            tensor_hat = np.zeros(dim)\n",
    "            \n",
    "            # Update X\n",
    "            for p in range(len(dim)):\n",
    "                lam = alpha[p]/rho\n",
    "                gamma = lam\n",
    "                tmp_p = svt_hoc(ten2mat(Z_tensor- T/rho, p), lam, gamma, theta)\n",
    "                tensor_hat += alpha[p]*mat2ten(tmp_p, dim, p)\n",
    "                #tensor_hat += alpha[p] * mat2ten(svt_tnn(ten2mat(Z_tensor - T / rho, p), \n",
    "                #                                         alpha[p] / rho, theta), dim, p)\n",
    "                \n",
    "            # Update Z\n",
    "            temp0 = rho / lambda0 * ten2mat(tensor_hat + T / rho, 0)\n",
    "            mat = np.zeros((dim[0], dim_time))\n",
    "            for m in range(dim[0]):\n",
    "                mat[m, :] = spsolve(temp[m] + rho * iden / lambda0, temp0[m, :])\n",
    "            Z[pos_missing] = mat[pos_missing]\n",
    "            Z_tensor = mat2ten(Z, dim, 0)\n",
    "            \n",
    "            # Update T\n",
    "            T = T + rho * (tensor_hat - Z_tensor)\n",
    "        \n",
    "        # Update A\n",
    "        for m in range(dim[0]):\n",
    "            A[m, :] = np.linalg.lstsq(Z[m, ind].T, Z[m, max_lag :], rcond = None)[0]\n",
    "        mat_hat = ten2mat(tensor_hat, 0)\n",
    "        \n",
    "        \n",
    "        tol = np.linalg.norm((mat_hat - last_mat), 'fro') / snorm\n",
    "        last_mat = mat_hat.copy()\n",
    "        it += 1\n",
    "        if it % 20 == 0:\n",
    "            print(\"iter\", it, \"tole = %.5f\" % tol)\n",
    "            #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "            \n",
    "        used_time += time.time() - start_time\n",
    "        \n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "    #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "    mape = compute_mape(dense_test, tensor_hat[pos_test])\n",
    "    rmse = compute_rmse(dense_test, tensor_hat[pos_test])\n",
    "    \n",
    "    return tensor_hat, used_time, mape, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c8adc",
   "metadata": {},
   "source": [
    "## LATC+HOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "896983b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THOP\n",
    "def hop_shrinkage(vec, lam, p):\n",
    "    tmp = np.abs(vec)-(lam**(2-p))*(np.abs(vec)**(p-1))\n",
    "    return np.sign(vec)*ReLU(tmp)\n",
    "\n",
    "def svt_hop(mat, lam, p, theta=0.1):    \n",
    "    u, s, v = svd_(mat)\n",
    "    ss = s.copy()\n",
    "    r = int(np.ceil(theta * len(s)))\n",
    "    #r = 15\n",
    "    ss[r:] = hop_shrinkage(s[r:], lam, p)\n",
    "    idx = np.where(ss > 0)[0]\n",
    "    return u[:, idx] @ np.diag(ss[idx]) @ v[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab463057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latc_hop(dense_tensor, sparse_tensor, time_lags, alpha, rho0, lambda0, theta, rhofac, p_hop,\n",
    "             epsilon = 1e-4, maxiter = 200, K = 3):\n",
    "    \"\"\" Truncated hybrid-ordinary Cauchy (THOC) \"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    dim_time = int(np.prod(dim) / dim[0])\n",
    "    d = len(time_lags)\n",
    "    max_lag = np.max(time_lags)\n",
    "    sparse_mat = ten2mat(sparse_tensor, 0)\n",
    "    pos_missing = np.where(sparse_mat == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    dense_test = dense_tensor[pos_test]\n",
    "    del dense_tensor\n",
    "    \n",
    "    # Initialize T, Z, A\n",
    "    T = np.zeros(dim)\n",
    "    Z_tensor = sparse_tensor.copy()\n",
    "    Z = sparse_mat.copy()\n",
    "    A = 0.001 * np.random.rand(dim[0], d)\n",
    "    Psis = generate_Psi(dim_time, time_lags)\n",
    "    iden = sparse.coo_matrix((np.ones(dim_time), (np.arange(0, dim_time), np.arange(0, dim_time))), \n",
    "                             shape = (dim_time, dim_time))\n",
    "    it = 0\n",
    "    ind = np.zeros((d, dim_time - max_lag), dtype = np.int_)\n",
    "    for i in range(d):\n",
    "        ind[i, :] = np.arange(max_lag - time_lags[i], dim_time - time_lags[i])\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    rho = rho0\n",
    "    \n",
    "    used_time = 0\n",
    "    sigmafac = np.sqrt(2)\n",
    "    #p_hop = 0.1\n",
    "    \n",
    "    # Main loop\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        temp = []\n",
    "        for m in range(dim[0]):\n",
    "            Psis0 = Psis.copy()\n",
    "            for i in range(d):\n",
    "                Psis0[i + 1] = A[m, i] * Psis[i + 1]\n",
    "            B = Psis0[0] - sum(Psis0[1 :])\n",
    "            temp.append(B.T @ B)\n",
    "            \n",
    "        # loop for ADMM\n",
    "        for k in range(K):\n",
    "            rho = min(rho * rhofac, 1e5)\n",
    "            tensor_hat = np.zeros(dim)\n",
    "            \n",
    "            # Update X\n",
    "            for p in range(len(dim)):\n",
    "                lam = alpha[p]/rho\n",
    "                gamma = lam\n",
    "                tmp_p = svt_hop(ten2mat(Z_tensor- T/rho, p), lam, p_hop, theta)\n",
    "                tensor_hat += alpha[p]*mat2ten(tmp_p, dim, p)\n",
    "                #tensor_hat += alpha[p] * mat2ten(svt_tnn(ten2mat(Z_tensor - T / rho, p), \n",
    "                #                                         alpha[p] / rho, theta), dim, p)\n",
    "                \n",
    "            # Update Z\n",
    "            temp0 = rho / lambda0 * ten2mat(tensor_hat + T / rho, 0)\n",
    "            mat = np.zeros((dim[0], dim_time))\n",
    "            for m in range(dim[0]):\n",
    "                mat[m, :] = spsolve(temp[m] + rho * iden / lambda0, temp0[m, :])\n",
    "            Z[pos_missing] = mat[pos_missing]\n",
    "            Z_tensor = mat2ten(Z, dim, 0)\n",
    "            \n",
    "            # Update T\n",
    "            T = T + rho * (tensor_hat - Z_tensor)\n",
    "        \n",
    "        # Update A\n",
    "        for m in range(dim[0]):\n",
    "            A[m, :] = np.linalg.lstsq(Z[m, ind].T, Z[m, max_lag :], rcond = None)[0]\n",
    "        mat_hat = ten2mat(tensor_hat, 0)\n",
    "        \n",
    "        \n",
    "        tol = np.linalg.norm((mat_hat - last_mat), 'fro') / snorm\n",
    "        last_mat = mat_hat.copy()\n",
    "        it += 1\n",
    "        if it % 20 == 0:\n",
    "            print(\"iter\", it, \"tole = %.5f\" % tol)\n",
    "            #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "            \n",
    "        used_time += time.time() - start_time\n",
    "        \n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "    #print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "    mape = compute_mape(dense_test, tensor_hat[pos_test])\n",
    "    rmse = compute_rmse(dense_test, tensor_hat[pos_test])\n",
    "    \n",
    "    return tensor_hat, used_time, mape, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771d259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc16cabe",
   "metadata": {},
   "source": [
    "## PEMv (traffic volume) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d46f295-637c-47d0-b75c-8cf020c2dd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 288, 31)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "## Random Missing (RM)\n",
    "#dense_tensor = scipy.io.loadmat('huangzhou.mat')['tensor'].transpose(0, 2, 1)\n",
    "\n",
    "tensor = scipy.io.loadmat('dataset/PEMS08/pems08_288_62_170.mat')\n",
    "dense_tensor = tensor['T']\n",
    "dense_tensor = dense_tensor.transpose(2,0,1)\n",
    "#dense_tensor = scipy.io.loadmat('PeMS-dataset/PEMS08/pems08_288_62_170.mat')\n",
    "dense_tensor = dense_tensor[:,:,0:31]\n",
    "dim1, dim2, dim3 = dense_tensor.shape\n",
    "dim = dense_tensor.shape\n",
    "\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26de81-4c43-4d90-bb3d-bb2d74db93d4",
   "metadata": {},
   "source": [
    "## Simulation code ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74703568-5743-42cf-bc71-bd54bcb498c6",
   "metadata": {},
   "source": [
    "### RM 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27c8e57b-e4a5-4036-b884-5c87bc1d1cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern RM missing rate = 0.3\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00215\n",
      "iter 40 tole = 0.00029\n",
      "mape 7.910571081913188\n",
      "rmse 19.88956693233205\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00211\n",
      "iter 40 tole = 0.00029\n",
      "mape 8.002325583525\n",
      "rmse 19.97249495351229\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00240\n",
      "iter 40 tole = 0.00029\n",
      "mape 7.958033092716965\n",
      "rmse 19.965672772973182\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00220\n",
      "iter 40 tole = 0.00030\n",
      "mape 7.906474147855737\n",
      "rmse 19.93925264684549\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00211\n",
      "iter 40 tole = 0.00029\n",
      "mape 7.965203844403189\n",
      "rmse 19.920954970402242\n",
      "1815.1793808937073\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "\n",
    "#mape5_latc = []\n",
    "#rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "mape5_hop = []\n",
    "rmse5_hop = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.3\n",
    "missing_case = \"RM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "        #alpha = [0.1,0.8,0.1]\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "        #alpha = np.ones(3)/3\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 4\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "        #alpha = np.ones(3)/3\n",
    "\n",
    "    print(\"lag\", time_lags)\n",
    "\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 25\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #print(\"MAPE:\", mape_latc*100)\n",
    "    #print(\"RMAE:\", rmse_latc)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "\n",
    "    ### THOC ###\n",
    "    #print(\"THOC\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hoc = 0.05\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                  alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    print(\"MAPE:\", mape_hoc*100)\n",
    "    print(\"RMAE:\", rmse_hoc)\n",
    "    mape5_hoc.append(mape_hoc)\n",
    "    rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP  ###\n",
    "    #print(\"THOP\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hop = 0.05\n",
    "    p_hop = 0.5\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hop, mape_hop, rmse_hop = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                   alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    print(\"mape\", mape_hop*100)\n",
    "    print(\"rmse\", rmse_hop)\n",
    "    mape5_hop3.append(mape_hop)\n",
    "    rmse5_hop3.append(rmse_hop)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c46fc766-08e0-4698-aee3-663ea63bdd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 7.95\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 19.94\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "#print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "#print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9541ae-5c87-42b3-a117-661db6de8fc6",
   "metadata": {},
   "source": [
    "### RM 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ef8698b-4e7f-47af-ad71-255404a602eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern RM missing rate = 0.7\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00597\n",
      "iter 40 tole = 0.00117\n",
      "iter 60 tole = 0.00012\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00599\n",
      "iter 40 tole = 0.00115\n",
      "iter 60 tole = 0.00012\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00601\n",
      "iter 40 tole = 0.00121\n",
      "iter 60 tole = 0.00012\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00600\n",
      "iter 40 tole = 0.00121\n",
      "iter 60 tole = 0.00013\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00600\n",
      "iter 40 tole = 0.00119\n",
      "iter 60 tole = 0.00012\n",
      "2305.9361000061035\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "\n",
    "#mape5_latc = []\n",
    "#rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "mape5_hop = []\n",
    "rmse5_hop = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.7\n",
    "missing_case = \"RM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "        #alpha = [0.1,0.8,0.1]\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "        #alpha = np.ones(3)/3\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 4\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "        #alpha = np.ones(3)/3\n",
    "\n",
    "    print(\"lag\", time_lags)\n",
    "\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 25\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #print(\"MAPE:\", mape_latc*100)\n",
    "    #print(\"RMAE:\", rmse_latc)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "\n",
    "    ### THOC ###\n",
    "    #print(\"THOC\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hoc = 0.03\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                  alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    print(\"MAPE:\", mape_hoc*100)\n",
    "    print(\"RMAE:\", rmse_hoc)\n",
    "    mape5_hoc.append(mape_hoc)\n",
    "    rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP  ###\n",
    "    #print(\"THOP\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hop = 0.03\n",
    "    p_hop = 0.5\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hop, mape_hop, rmse_hop = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                   alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    print(\"mape\", mape_hop*100)\n",
    "    print(\"rmse\", rmse_hop)\n",
    "    mape5_hop3.append(mape_hop)\n",
    "    rmse5_hop3.append(rmse_hop)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40efcfc5-9932-4393-96bb-2b18a146ce1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 8.89\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 21.98\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "#print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "#print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ba6967-7adf-4dfb-8e2e-00fd0eaec593",
   "metadata": {},
   "source": [
    "### NM 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f9d8f29-7c02-4945-b6ae-c1de8f96bbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern NM missing rate = 0.3\n",
      "lag [1 2 3 4 5 6]\n",
      "LATC-HOP3 1\n",
      "iter 20 tole = 0.00120\n",
      "iter 40 tole = 0.00009\n",
      "MAPE 11.78002054272138\n",
      "RMSE 32.469032365247166\n",
      "lag [1 2 3 4 5 6]\n",
      "LATC-HOP3 2\n",
      "iter 20 tole = 0.00117\n",
      "iter 40 tole = 0.00010\n",
      "MAPE 11.977292916254036\n",
      "RMSE 31.27433197739748\n",
      "lag [1 2 3 4 5 6]\n",
      "LATC-HOP3 3\n",
      "iter 20 tole = 0.00112\n",
      "iter 40 tole = 0.00010\n",
      "MAPE 12.522608563142565\n",
      "RMSE 32.4036565849305\n",
      "lag [1 2 3 4 5 6]\n",
      "LATC-HOP3 4\n",
      "iter 20 tole = 0.00118\n",
      "iter 40 tole = 0.00010\n",
      "MAPE 12.103894162546535\n",
      "RMSE 32.78913851685067\n",
      "lag [1 2 3 4 5 6]\n",
      "LATC-HOP3 5\n",
      "iter 20 tole = 0.00114\n",
      "iter 40 tole = 0.00010\n",
      "MAPE 11.055650945645311\n",
      "RMSE 31.843427733604845\n",
      "1368.641098022461\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "\n",
    "#mape5_latc = []\n",
    "#rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "mape5_hop = []\n",
    "rmse5_hop = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.3\n",
    "missing_case = \"NM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "        #alpha = [0.1,0.8,0.1]\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "        #alpha = np.ones(3)/3\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 4\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "        #alpha = np.ones(3)/3\n",
    "\n",
    "    print(\"lag\", time_lags)\n",
    "\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 25\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #print(\"MAPE:\", mape_latc*100)\n",
    "    #print(\"RMAE:\", rmse_latc)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "\n",
    "    ### THOC ###\n",
    "    #print(\"THOC\", seed)\n",
    "    c = 0.1\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hoc = 0.01\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                  alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    print(\"MAPE:\", mape_hoc*100)\n",
    "    print(\"RMAE:\", rmse_hoc)\n",
    "    mape5_hoc.append(mape_hoc)\n",
    "    rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP  ###\n",
    "    #print(\"THOP\", seed)\n",
    "    c = 1\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hop = 0.05\n",
    "    p_hop = 0.5\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hop, mape_hop, rmse_hop = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                   alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    print(\"mape\", mape_hop*100)\n",
    "    print(\"rmse\", rmse_hop)\n",
    "    mape5_hop3.append(mape_hop)\n",
    "    rmse5_hop3.append(rmse_hop)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a43ed8e2-4d3b-428a-9b26-9ee739178e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 11.89\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 32.16\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "#print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "#print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea237c5-4cad-45b4-84ab-8dadd80e7bcf",
   "metadata": {},
   "source": [
    "### NM 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3014b26-38b3-49ca-a353-4f06b14e81d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern NM missing rate = 0.7\n",
      "lags [1 2 3 4 5 6]\n",
      "LATC-HOC 1\n",
      "iter 20 tole = 0.00405\n",
      "iter 40 tole = 0.00046\n",
      "mape: 13.979643099389211\n",
      "rmse 36.796417716720946\n",
      "lags [1 2 3 4 5 6]\n",
      "LATC-HOC 2\n",
      "iter 20 tole = 0.00387\n",
      "iter 40 tole = 0.00047\n",
      "mape: 14.000163445252472\n",
      "rmse 35.51087341858869\n",
      "lags [1 2 3 4 5 6]\n",
      "LATC-HOC 3\n",
      "iter 20 tole = 0.00403\n",
      "iter 40 tole = 0.00044\n",
      "mape: 14.113695465976514\n",
      "rmse 36.86434662628388\n",
      "lags [1 2 3 4 5 6]\n",
      "LATC-HOC 4\n",
      "iter 20 tole = 0.00395\n",
      "iter 40 tole = 0.00049\n",
      "mape: 13.9676275625115\n",
      "rmse 35.39644715460936\n",
      "lags [1 2 3 4 5 6]\n",
      "LATC-HOC 5\n",
      "iter 20 tole = 0.00394\n",
      "iter 40 tole = 0.00051\n",
      "mape: 13.940535727259789\n",
      "rmse 36.55228347300118\n",
      "1718.3546681404114\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "\n",
    "#mape5_latc = []\n",
    "#rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "mape5_hop = []\n",
    "rmse5_hop = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.7\n",
    "missing_case = \"NM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "        #alpha = [0.1,0.8,0.1]\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "        #alpha = np.ones(3)/3\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 4\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "        #alpha = np.ones(3)/3\n",
    "\n",
    "    print(\"lag\", time_lags)\n",
    "\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 25\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #print(\"MAPE:\", mape_latc*100)\n",
    "    #print(\"RMAE:\", rmse_latc)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "\n",
    "    ### THOC ###\n",
    "    #print(\"THOC\", seed)\n",
    "    c = 0.1\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hoc = 0.01\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                  alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    print(\"MAPE:\", mape_hoc*100)\n",
    "    print(\"RMAE:\", rmse_hoc)\n",
    "    mape5_hoc.append(mape_hoc)\n",
    "    rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP  ###\n",
    "    #print(\"THOP\", seed)\n",
    "    c = 1\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hop = 0.01\n",
    "    p_hop = 0.5\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hop, mape_hop, rmse_hop = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                   alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    print(\"mape\", mape_hop*100)\n",
    "    print(\"rmse\", rmse_hop)\n",
    "    mape5_hop3.append(mape_hop)\n",
    "    rmse5_hop3.append(rmse_hop)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d241343-fd13-45a9-a8e4-a2456f44c454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: 14.00\n",
      "LATC-HOP(p=0.3): nan\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: 36.22\n",
      "LATC-HOP(p=0.3): nan\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "#print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "#print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1076b96a-f277-4869-85cb-6112209abb07",
   "metadata": {},
   "source": [
    "### BM 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9bffca39-34f0-4202-867b-3ecf6661c18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern BM missing rate = 0.3\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00191\n",
      "iter 40 tole = 0.00025\n",
      "mape 9.098383024218483\n",
      "rmse 22.59040850937538\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00196\n",
      "iter 40 tole = 0.00026\n",
      "mape 9.280968572837143\n",
      "rmse 22.502880021255958\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00192\n",
      "iter 40 tole = 0.00024\n",
      "mape 9.027498276477433\n",
      "rmse 22.670290679675237\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00185\n",
      "iter 40 tole = 0.00024\n",
      "mape 9.17414155601705\n",
      "rmse 22.55253313736204\n",
      "lag [1 2 3 4 5 6]\n",
      "iter 20 tole = 0.00185\n",
      "iter 40 tole = 0.00024\n",
      "mape 8.995212035962407\n",
      "rmse 22.047107174258443\n",
      "1632.7403428554535\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "\n",
    "#mape5_latc = []\n",
    "#rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "mape5_hop = []\n",
    "rmse5_hop = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.7\n",
    "missing_case = \"NM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "        #alpha = [0.1,0.8,0.1]\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "        #alpha = np.ones(3)/3\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 4\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "        #alpha = np.ones(3)/3\n",
    "\n",
    "    print(\"lag\", time_lags)\n",
    "\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 25\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #print(\"MAPE:\", mape_latc*100)\n",
    "    #print(\"RMAE:\", rmse_latc)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "\n",
    "    ### THOC ###\n",
    "    #print(\"THOC\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hoc = 0.03\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                  alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    print(\"MAPE:\", mape_hoc*100)\n",
    "    print(\"RMAE:\", rmse_hoc)\n",
    "    mape5_hoc.append(mape_hoc)\n",
    "    rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP  ###\n",
    "    #print(\"THOP\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hop = 0.03\n",
    "    p_hop = 0.2\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hop, mape_hop, rmse_hop = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                   alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    print(\"mape\", mape_hop*100)\n",
    "    print(\"rmse\", rmse_hop)\n",
    "    mape5_hop3.append(mape_hop)\n",
    "    rmse5_hop3.append(rmse_hop)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e1e4baf-b725-46db-8284-e23f8be40168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 9.12\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 22.47\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "#print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "#print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop),\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccc1d9b-2512-427c-95f5-c7e96cd34f43",
   "metadata": {},
   "source": [
    "### BM 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc792ee1-af46-44a6-8a40-56be0afa7c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "missing pattern BM missing rate = 0.7\n",
      "lag [1 2 3 4 5 6]\n",
      "LATC-HOP3 1\n",
      "iter 20 tole = 0.00559\n",
      "iter 40 tole = 0.00083\n",
      "lag [1 2 3 4 5 6]\n",
      "LATC-HOP3 2\n",
      "iter 20 tole = 0.00528\n",
      "iter 40 tole = 0.00084\n",
      "lag [1 2 3 4 5 6]\n",
      "LATC-HOP3 3\n",
      "iter 20 tole = 0.00574\n",
      "iter 40 tole = 0.00105\n",
      "lag [1 2 3 4 5 6]\n",
      "LATC-HOP3 4\n",
      "iter 20 tole = 0.00513\n",
      "iter 40 tole = 0.00080\n",
      "lag [1 2 3 4 5 6]\n",
      "LATC-HOP3 5\n",
      "iter 20 tole = 0.00538\n",
      "iter 40 tole = 0.00091\n",
      "1932.4174537658691\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "time_lags = np.arange(1,7)\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "#### Main simulations ####\n",
    "\n",
    "#mape5_latc = []\n",
    "#rmse5_latc = []\n",
    "\n",
    "mape5_hoc = []\n",
    "rmse5_hoc = []\n",
    "\n",
    "mape5_hop = []\n",
    "rmse5_hop = []\n",
    "\n",
    "# missing rates and pattern\n",
    "missing_rate = 0.7\n",
    "missing_case = \"NM\"\n",
    "\n",
    "print(\"start\")\n",
    "print(\"missing pattern\", missing_case, \"missing rate =\", missing_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for seed in range(1,6):\n",
    "    ### generate missing entries ###\n",
    "    np.random.seed(seed+999)\n",
    "    \n",
    "    if missing_case == 'RM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "        #alpha = [0.1,0.8,0.1]\n",
    "    elif missing_case == 'NM':\n",
    "        sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "        #alpha = np.ones(3)/3\n",
    "    else:\n",
    "        dim_time = dim2 * dim3\n",
    "        block_window = 4\n",
    "        vec = np.random.rand(int(dim_time / block_window))\n",
    "        temp = np.array([vec] * block_window)\n",
    "        vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "        sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :], \n",
    "                                np.array([dim1, dim2, dim3]), 0)\n",
    "        #alpha = np.ones(3)/3\n",
    "\n",
    "    print(\"lag\", time_lags)\n",
    "\n",
    "    ### LATC ###\n",
    "    #print(\"LATC\", seed)\n",
    "    #c = 10\n",
    "    #theta = 25\n",
    "    #rho = 1e-5\n",
    "    #lambda0 = c * rho\n",
    "\n",
    "    #tensor_hat, time_latc, mape_latc, rmse_latc = latc(dense_tensor, sparse_tensor, time_lags, \n",
    "    #                                                   alpha, rho, lambda0, theta)\n",
    "    #print(\"MAPE:\", mape_latc*100)\n",
    "    #print(\"RMAE:\", rmse_latc)\n",
    "    #mape5_latc.append(mape_latc)\n",
    "    #rmse5_latc.append(rmse_latc)\n",
    "\n",
    "    ### THOC ###\n",
    "    #print(\"THOC\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hoc = 0.03\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hoc, mape_hoc, rmse_hoc = latc_hoc(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                  alpha, rho, lambda0, theta_hoc, rhofac, epsilon=1e-4)\n",
    "    print(\"MAPE:\", mape_hoc*100)\n",
    "    print(\"RMAE:\", rmse_hoc)\n",
    "    mape5_hoc.append(mape_hoc)\n",
    "    rmse5_hoc.append(rmse_hoc)\n",
    "    \n",
    "    ### LATC-HOP  ###\n",
    "    #print(\"THOP\", seed)\n",
    "    c = 10\n",
    "    rho = 1e-5\n",
    "    lambda0 = c * rho\n",
    "    theta_hop = 0.03\n",
    "    p_hop = 0.2\n",
    "    \n",
    "    rhofac = 1.05\n",
    "    Xest, time_hop, mape_hop, rmse_hop = latc_hop(dense_tensor, sparse_tensor, time_lags, \n",
    "                                                   alpha, rho, lambda0, theta_hop, rhofac, p_hop, epsilon=1e-4)\n",
    "    print(\"mape\", mape_hop*100)\n",
    "    print(\"rmse\", rmse_hop)\n",
    "    mape5_hop3.append(mape_hop)\n",
    "    rmse5_hop3.append(rmse_hop)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf19b172-cb56-4079-8deb-a58fc7339eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(%) comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 10.97\n",
      "LATC-HOP(p=0.6): nan\n",
      "--------\n",
      "RMSE comparison\n",
      "LATC: nan\n",
      "LATC-HOC: nan\n",
      "LATC-HOP(p=0.3): 26.91\n",
      "LATC-HOP(p=0.6): nan\n"
     ]
    }
   ],
   "source": [
    "print(\"MAPE(%) comparison\")\n",
    "#print(\"LATC:\", format(np.mean(mape5_latc)*100,\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(mape5_hoc)*100,\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(mape5_hop)*100,\".2f\"))\n",
    "print(\"--------\")\n",
    "print(\"RMSE comparison\")\n",
    "#print(\"LATC:\", format(np.mean(rmse5_latc),\".2f\"))\n",
    "print(\"LATC-HOC:\", format(np.mean(rmse5_hoc),\".2f\"))\n",
    "print(\"LATC-HOP(p=0.3):\", format(np.mean(rmse5_hop),\".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e124be1-15ef-4f68-b69b-7f153c344f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
